{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c28bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import elephant\n",
    "import quantities as pq\n",
    "import neo\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from elephant.conversion import BinnedSpikeTrain\n",
    "from elephant.spike_train_correlation import correlation_coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44748fcb",
   "metadata": {},
   "source": [
    "Create dataframes storing the spiketimes of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc80bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spikes_df(path):\n",
    "    for p in path.iterdir():\n",
    "        for f in p.iterdir():\n",
    "            if f.is_dir():\n",
    "                # in each folder res\\seed_x\n",
    "                # create new empty dataframe\n",
    "                df = pd.DataFrame(columns=['sender','time_ms'])\n",
    "                for l in f.iterdir():\n",
    "                    # for each file in folder\n",
    "                    if Path(l).suffix == '.dat':\n",
    "                        # if file is spike data file, add to dataframe\n",
    "                        a = pd.read_csv(l,skiprows=2,sep='\\t')\n",
    "                        df = df.append(a)\n",
    "                # gone through all files in folder. Save the df to pkl file.\n",
    "                df.to_pickle(r'{}\\spike_data.pkl'.format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a74884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data\\\\droop')\n",
    "create_spikes_df(path)\n",
    "\n",
    "path = Path('C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data\\\\equal')\n",
    "create_spikes_df(path)\n",
    "\n",
    "path = Path('C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data\\\\continuous')\n",
    "create_spikes_df(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c043a9",
   "metadata": {},
   "source": [
    "Calculate CV values and save them in dataframes in csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b56a9437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cvs(spike_data):\n",
    "    \"\"\"\n",
    "    Get the CV for each neuron recorded. \n",
    "    \n",
    "    CV = standard_deviation(ISIs)/mean(ISIs)\n",
    "    \"\"\"\n",
    "    cvs = []\n",
    "     \n",
    "    spike_data = spike_data.sort_values(by='time_ms')\n",
    "    grouped = spike_data.groupby(spike_data['sender'])\n",
    "\n",
    "    for name, group in grouped:\n",
    "            \"\"\"\n",
    "            Each group is senders and times for one value of senders. That is, we iterate through all \n",
    "            neurons. And the times for each neuron is in sorted order. Therefore, the cvs\n",
    "            returned must have the same order. So cvs contain cv of neuron 1, then neuron 2 .... then neuron N.\n",
    "            \"\"\"\n",
    "            t = np.asarray(group['time_ms'])\n",
    "            spiketrain = neo.core.SpikeTrain(t * pq.ms, t_start=0*pq.ms, t_stop=10000*pq.ms)\n",
    "            isi = elephant.statistics.isi(spiketrain)\n",
    "            cv = elephant.statistics.cv(isi)\n",
    "            cvs.append(cv)\n",
    "            \n",
    "    return cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cfb4f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cv_dfs(path):\n",
    "    for p in path.iterdir():\n",
    "        # resolution folder\n",
    "        cv_list = list()\n",
    "        for f in p.iterdir():\n",
    "            if f.is_dir():\n",
    "                data = pd.read_pickle(r'{}\\spike_data.pkl'.format(f))\n",
    "                cvs = get_cvs(data)\n",
    "                cv_list.append(cvs)\n",
    "        # iterated through all seed folders and calculated CV values.\n",
    "        df = pd.DataFrame(cv_list) # save cvs to dataframe\n",
    "        df.to_csv(r'{}\\77175_cv.csv'.format(p)) # save as csv file      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78190290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1144: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "path = Path('C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data\\\\droop')\n",
    "create_cv_dfs(path)\n",
    "\n",
    "path = Path('C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data\\\\equal')\n",
    "create_cv_dfs(path)\n",
    "\n",
    "path = Path('C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data\\\\continuous')\n",
    "create_cv_dfs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cbc5a0",
   "metadata": {},
   "source": [
    "Calculate frs and save them in dataframes in pickle files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7bdbaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frs(spike_data):\n",
    "    \"\"\"\n",
    "    Get the FR for each neuron recorded. \n",
    "    \n",
    "    FR = number of spikes fired during simulation/time of simulation\n",
    "    \"\"\"\n",
    "    frs = []\n",
    "     \n",
    "    spike_data = spike_data.sort_values(by='time_ms')\n",
    "    grouped = spike_data.groupby(spike_data['sender'])\n",
    "\n",
    "    for name, group in grouped:\n",
    "            \"\"\"\n",
    "            Each group is senders and times for one value of senders. That is, we iterate through all \n",
    "            neurons. And the times for each neuron is in sorted order. Therefore, the cvs\n",
    "            returned must have the same order. So cvs contain cv of neuron 1, then neuron 2 .... then neuron N.\n",
    "            \"\"\"\n",
    "            t = np.asarray(group['time_ms'])\n",
    "            spiketrain = neo.core.SpikeTrain(t * pq.ms, t_start=0*pq.ms, t_stop=10000*pq.ms)\n",
    "            fr = elephant.statistics.mean_firing_rate(spiketrain)\n",
    "            frs.append(fr)\n",
    "            \n",
    "    return frs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8758b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fr_dfs(path):\n",
    "    for p in path.iterdir():\n",
    "        # resolution folder\n",
    "        fr_list = list()\n",
    "        for f in p.iterdir():\n",
    "            if f.is_dir():\n",
    "                data = pd.read_pickle(r'{}\\spike_data.pkl'.format(f))\n",
    "                frs = get_frs(data)\n",
    "                fr_list.append(frs)\n",
    "        # iterated through all seed folders and calculated FR values.\n",
    "        # some neruons dont spike, fill the missing spots with fr 0 instead of None\n",
    "        df = pd.DataFrame(fr_list).fillna(pq.quantity.Quantity(0,units='1/ms')) # save frs to dataframe\n",
    "        df.to_pickle(r'{}\\77175_fr.pkl'.format(p)) # save as csv file      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eca15bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data\\\\droop')\n",
    "create_fr_dfs(path)\n",
    "\n",
    "path = Path('C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data\\\\equal')\n",
    "create_fr_dfs(path)\n",
    "\n",
    "path = Path('C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data\\\\continuous')\n",
    "create_fr_dfs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ad4f2",
   "metadata": {},
   "source": [
    "Calculate CCs and save them in dataframes in csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29ca8a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ccs(data,bs=5):\n",
    "    spike_data = data.sort_values(by='time_ms')\n",
    "    grouped = spike_data.groupby(spike_data['sender'])\n",
    "    spike_trains = []\n",
    "    for name, group in grouped:\n",
    "        \"\"\"\n",
    "        The groups come in order, so that the first group is the first neuron in the population.\n",
    "        \"\"\"\n",
    "        t = np.asarray(group['time_ms'])\n",
    "        spiketrain = neo.core.SpikeTrain(t * pq.ms, t_start=0*pq.ms, t_stop=10000*pq.ms)\n",
    "        spike_trains.append(spiketrain)\n",
    "    \"\"\"\n",
    "    Now that we have all the spike trains, we can calculate the correlations between the first neuron in the population,\n",
    "    and the rest.\n",
    "    \"\"\"\n",
    "    correlations = []\n",
    "    for i in range(len(spike_trains)):\n",
    "        # could make sense to let range go from 1 and up, not include cc of first neruon with itself. But nice to have\n",
    "        # same length for this statistic as the others. And all models will have this so okay.\n",
    "        \n",
    "        # calculate cc matrix for the pair of spiketrains\n",
    "        cc_matrix = correlation_coefficient(BinnedSpikeTrain([spike_trains[i],spike_trains[0]], bin_size=bs*pq.ms))\n",
    "        # retrieve element not on diagonal\n",
    "        cc = cc_matrix[1,0]\n",
    "        correlations.append(cc)\n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ea0e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cc_dfs(path):\n",
    "    for p in path.iterdir():\n",
    "        # resolution folder\n",
    "        cc_list = list()\n",
    "        for f in p.iterdir():\n",
    "            if f.is_dir():\n",
    "                data = pd.read_pickle(r'{}\\spike_data.pkl'.format(f))\n",
    "                ccs = get_ccs(data)\n",
    "                cc_list.append(ccs)\n",
    "        # iterated through all seed folders and calculated CV values.\n",
    "        df = pd.DataFrame(cc_list).fillna(0) # save ccs to dataframe\n",
    "        df.to_csv(r'{}\\77175_cc5.csv'.format(p)) # save as csv file      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f97f30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 2 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n",
      "C:\\Users\\Nida\\anaconda3\\lib\\site-packages\\elephant\\conversion.py:1168: UserWarning: Binning discarded 1 last spike(s) of the input spiketrain\n",
      "  warnings.warn(\"Binning discarded {} last spike(s) of the \"\n"
     ]
    }
   ],
   "source": [
    "path = Path('C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data\\\\droop')\n",
    "create_cc_dfs(path)\n",
    "\n",
    "path = Path('C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data\\\\equal')\n",
    "create_cc_dfs(path)\n",
    "\n",
    "path = Path('C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data\\\\continuous')\n",
    "create_cc_dfs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f483a4de",
   "metadata": {},
   "source": [
    "Get all the statistics into variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30a3e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = 'C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data'\n",
    "typ = ['droop','equal']\n",
    "res = ['res_1_2','res_1_4','res_1_8','res_1_16','res_1_32','res_1_64',\n",
    "      'res_1_128','res_1_256']\n",
    "file = '77175_cv.csv'\n",
    "\n",
    "\n",
    "cv_1_2_droop = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[0],file),index_col=0)\n",
    "# do not have equal resolution 1/2\n",
    "\n",
    "\n",
    "cv_1_4_droop = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[1],file),index_col=0)\n",
    "cv_1_4_equal = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[1],file),index_col=0)\n",
    "\n",
    "cv_1_8_droop = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[2],file),index_col=0)\n",
    "cv_1_8_equal = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[2],file),index_col=0)\n",
    "\n",
    "cv_1_16_droop = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[3],file),index_col=0)\n",
    "cv_1_16_equal = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[3],file),index_col=0)\n",
    "\n",
    "cv_1_32_droop = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[4],file),index_col=0)\n",
    "cv_1_32_equal = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[4],file),index_col=0)\n",
    "\n",
    "cv_1_64_droop = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[5],file),index_col=0)\n",
    "cv_1_64_equal = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[5],file),index_col=0)\n",
    "\n",
    "cv_1_128_droop = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[6],file),index_col=0)\n",
    "cv_1_128_equal = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[6],file),index_col=0)\n",
    "\n",
    "cv_1_256_droop = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[7],file),index_col=0)\n",
    "cv_1_256_equal = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[7],file),index_col=0)\n",
    "\n",
    "cv_cont = pd.read_csv('C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data\\\\continuous\\\\res_1_8\\\\77175_cv.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d9d5850",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = 'C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data'\n",
    "typ = ['droop','equal']\n",
    "res = ['res_1_2','res_1_4','res_1_8','res_1_16','res_1_32','res_1_64',\n",
    "      'res_1_128','res_1_256']\n",
    "file = '77175_fr.pkl'\n",
    "\n",
    "\n",
    "fr_1_2_droop = pd.read_pickle(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[0],file) )\n",
    "# do not have equal resolution 1/2\n",
    "\n",
    "\n",
    "fr_1_4_droop = pd.read_pickle(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[1],file) )\n",
    "fr_1_4_equal = pd.read_pickle(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[1],file) )\n",
    "\n",
    "fr_1_8_droop = pd.read_pickle(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[2],file) )\n",
    "fr_1_8_equal = pd.read_pickle(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[2],file) )\n",
    "\n",
    "fr_1_16_droop = pd.read_pickle(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[3],file) )\n",
    "fr_1_16_equal = pd.read_pickle(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[3],file) )\n",
    "\n",
    "fr_1_32_droop = pd.read_pickle(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[4],file) )\n",
    "fr_1_32_equal = pd.read_pickle(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[4],file) )\n",
    "\n",
    "fr_1_64_droop = pd.read_pickle(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[5],file) )\n",
    "fr_1_64_equal = pd.read_pickle(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[5],file) )\n",
    "\n",
    "fr_1_128_droop = pd.read_pickle(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[6],file) )\n",
    "fr_1_128_equal = pd.read_pickle(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[6],file) )\n",
    "\n",
    "fr_1_256_droop = pd.read_pickle(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[7],file) )\n",
    "fr_1_256_equal = pd.read_pickle(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[7],file) )\n",
    "\n",
    "fr_cont = pd.read_pickle('C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data\\\\continuous\\\\res_1_8\\\\77175_fr.pkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dd6a092",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = 'C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data'\n",
    "typ = ['droop','equal']\n",
    "res = ['res_1_2','res_1_4','res_1_8','res_1_16','res_1_32','res_1_64',\n",
    "      'res_1_128','res_1_256']\n",
    "file = '77175_cc5.csv'\n",
    "\n",
    "\n",
    "cc5_1_2_droop = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[0],file),index_col=0)\n",
    "# do not have equal resolution 1/2\n",
    "\n",
    "\n",
    "cc5_1_4_droop = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[1],file),index_col=0)\n",
    "cc5_1_4_equal = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[1],file),index_col=0)\n",
    "\n",
    "cc5_1_8_droop = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[2],file),index_col=0)\n",
    "cc5_1_8_equal = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[2],file),index_col=0)\n",
    "\n",
    "cc5_1_16_droop = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[3],file),index_col=0)\n",
    "cc5_1_16_equal = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[3],file),index_col=0)\n",
    "\n",
    "cc5_1_32_droop = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[4],file),index_col=0)\n",
    "cc5_1_32_equal = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[4],file),index_col=0)\n",
    "\n",
    "cc5_1_64_droop = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[5],file),index_col=0)\n",
    "cc5_1_64_equal = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[5],file),index_col=0)\n",
    "\n",
    "cc5_1_128_droop = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[6],file),index_col=0)\n",
    "cc5_1_128_equal = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[6],file),index_col=0)\n",
    "\n",
    "cc5_1_256_droop = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[0],res[7],file),index_col=0)\n",
    "cc5_1_256_equal = pd.read_csv(r'{}\\{}\\{}\\{}'.format(main_path,typ[1],res[7],file),index_col=0)\n",
    "\n",
    "cc5_cont = pd.read_csv('C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data\\\\continuous\\\\res_1_8\\\\77175_cc5.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55f4b53",
   "metadata": {},
   "source": [
    "Create the multiindex dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7030f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = ['droop','equal','continuous'] #what type of model\n",
    "second = [2,4,8,16,32,64,128,256] # what type of resolution\n",
    "third = [1,2,3,4,5,6,7,8,9,10] # what seed\n",
    "fourth = [i for i in range(0,1065)] # we have 1065 neurons \n",
    "arrays = [first, second, third, fourth]\n",
    "\n",
    "\n",
    "index = pd.MultiIndex.from_product(arrays)\n",
    "columns = ['CV','FR','CC_5']\n",
    "\n",
    "df = pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "# indexes must be sorted to make more effective and avoid warnings.\n",
    "df2 = df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9192feab",
   "metadata": {},
   "source": [
    "FIll in the dataframe with all our values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a311465",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',2,1)]['CV'][:] = cv_1_2_droop.iloc[0]\n",
    "df2.loc[('droop',2,2)]['CV'][:] = cv_1_2_droop.iloc[1]\n",
    "df2.loc[('droop',2,3)]['CV'][:] = cv_1_2_droop.iloc[2]\n",
    "df2.loc[('droop',2,4)]['CV'][:] = cv_1_2_droop.iloc[3]\n",
    "df2.loc[('droop',2,5)]['CV'][:] = cv_1_2_droop.iloc[4]\n",
    "df2.loc[('droop',2,6)]['CV'][:] = cv_1_2_droop.iloc[5]\n",
    "df2.loc[('droop',2,7)]['CV'][:] = cv_1_2_droop.iloc[6]\n",
    "df2.loc[('droop',2,8)]['CV'][:] = cv_1_2_droop.iloc[7]\n",
    "df2.loc[('droop',2,9)]['CV'][:] = cv_1_2_droop.iloc[8]\n",
    "df2.loc[('droop',2,10)]['CV'][:] = cv_1_2_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ae4cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',4,1)]['CV'][:] = cv_1_4_droop.iloc[0]\n",
    "df2.loc[('droop',4,2)]['CV'][:] = cv_1_4_droop.iloc[1]\n",
    "df2.loc[('droop',4,3)]['CV'][:] = cv_1_4_droop.iloc[2]\n",
    "df2.loc[('droop',4,4)]['CV'][:] = cv_1_4_droop.iloc[3]\n",
    "df2.loc[('droop',4,5)]['CV'][:] = cv_1_4_droop.iloc[4]\n",
    "df2.loc[('droop',4,6)]['CV'][:] = cv_1_4_droop.iloc[5]\n",
    "df2.loc[('droop',4,7)]['CV'][:] = cv_1_4_droop.iloc[6]\n",
    "df2.loc[('droop',4,8)]['CV'][:] = cv_1_4_droop.iloc[7]\n",
    "df2.loc[('droop',4,9)]['CV'][:] = cv_1_4_droop.iloc[8]\n",
    "df2.loc[('droop',4,10)]['CV'][:] = cv_1_4_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff426713",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',8,1)]['CV'][:] = cv_1_8_droop.iloc[0]\n",
    "df2.loc[('droop',8,2)]['CV'][:] = cv_1_8_droop.iloc[1]\n",
    "df2.loc[('droop',8,3)]['CV'][:] = cv_1_8_droop.iloc[2]\n",
    "df2.loc[('droop',8,4)]['CV'][:] = cv_1_8_droop.iloc[3]\n",
    "df2.loc[('droop',8,5)]['CV'][:] = cv_1_8_droop.iloc[4]\n",
    "df2.loc[('droop',8,6)]['CV'][:] = cv_1_8_droop.iloc[5]\n",
    "df2.loc[('droop',8,7)]['CV'][:] = cv_1_8_droop.iloc[6]\n",
    "df2.loc[('droop',8,8)]['CV'][:] = cv_1_8_droop.iloc[7]\n",
    "df2.loc[('droop',8,9)]['CV'][:] = cv_1_8_droop.iloc[8]\n",
    "df2.loc[('droop',8,10)]['CV'][:] = cv_1_8_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7d34df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',16,1)]['CV'][:] = cv_1_16_droop.iloc[0]\n",
    "df2.loc[('droop',16,2)]['CV'][:] = cv_1_16_droop.iloc[1]\n",
    "df2.loc[('droop',16,3)]['CV'][:] = cv_1_16_droop.iloc[2]\n",
    "df2.loc[('droop',16,4)]['CV'][:] = cv_1_16_droop.iloc[3]\n",
    "df2.loc[('droop',16,5)]['CV'][:] = cv_1_16_droop.iloc[4]\n",
    "df2.loc[('droop',16,6)]['CV'][:] = cv_1_16_droop.iloc[5]\n",
    "df2.loc[('droop',16,7)]['CV'][:] = cv_1_16_droop.iloc[6]\n",
    "df2.loc[('droop',16,8)]['CV'][:] = cv_1_16_droop.iloc[7]\n",
    "df2.loc[('droop',16,9)]['CV'][:] = cv_1_16_droop.iloc[8]\n",
    "df2.loc[('droop',16,10)]['CV'][:] = cv_1_16_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0113a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',32,1)]['CV'][:] = cv_1_32_droop.iloc[0]\n",
    "df2.loc[('droop',32,2)]['CV'][:] = cv_1_32_droop.iloc[1]\n",
    "df2.loc[('droop',32,3)]['CV'][:] = cv_1_32_droop.iloc[2]\n",
    "df2.loc[('droop',32,4)]['CV'][:] = cv_1_32_droop.iloc[3]\n",
    "df2.loc[('droop',32,5)]['CV'][:] = cv_1_32_droop.iloc[4]\n",
    "df2.loc[('droop',32,6)]['CV'][:] = cv_1_32_droop.iloc[5]\n",
    "df2.loc[('droop',32,7)]['CV'][:] = cv_1_32_droop.iloc[6]\n",
    "df2.loc[('droop',32,8)]['CV'][:] = cv_1_32_droop.iloc[7]\n",
    "df2.loc[('droop',32,9)]['CV'][:] = cv_1_32_droop.iloc[8]\n",
    "df2.loc[('droop',32,10)]['CV'][:] = cv_1_32_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0e08c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',64,1)]['CV'][:] = cv_1_64_droop.iloc[0]\n",
    "df2.loc[('droop',64,2)]['CV'][:] = cv_1_64_droop.iloc[1]\n",
    "df2.loc[('droop',64,3)]['CV'][:] = cv_1_64_droop.iloc[2]\n",
    "df2.loc[('droop',64,4)]['CV'][:] = cv_1_64_droop.iloc[3]\n",
    "df2.loc[('droop',64,5)]['CV'][:] = cv_1_64_droop.iloc[4]\n",
    "df2.loc[('droop',64,6)]['CV'][:] = cv_1_64_droop.iloc[5]\n",
    "df2.loc[('droop',64,7)]['CV'][:] = cv_1_64_droop.iloc[6]\n",
    "df2.loc[('droop',64,8)]['CV'][:] = cv_1_64_droop.iloc[7]\n",
    "df2.loc[('droop',64,9)]['CV'][:] = cv_1_64_droop.iloc[8]\n",
    "df2.loc[('droop',64,10)]['CV'][:] = cv_1_64_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaeb5474",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',128,1)]['CV'][:] = cv_1_128_droop.iloc[0]\n",
    "df2.loc[('droop',128,2)]['CV'][:] = cv_1_128_droop.iloc[1]\n",
    "df2.loc[('droop',128,3)]['CV'][:] = cv_1_128_droop.iloc[2]\n",
    "df2.loc[('droop',128,4)]['CV'][:] = cv_1_128_droop.iloc[3]\n",
    "df2.loc[('droop',128,5)]['CV'][:] = cv_1_128_droop.iloc[4]\n",
    "df2.loc[('droop',128,6)]['CV'][:] = cv_1_128_droop.iloc[5]\n",
    "df2.loc[('droop',128,7)]['CV'][:] = cv_1_128_droop.iloc[6]\n",
    "df2.loc[('droop',128,8)]['CV'][:] = cv_1_128_droop.iloc[7]\n",
    "df2.loc[('droop',128,9)]['CV'][:] = cv_1_128_droop.iloc[8]\n",
    "df2.loc[('droop',128,10)]['CV'][:] = cv_1_128_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "954ad41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',256,1)]['CV'][:] = cv_1_256_droop.iloc[0]\n",
    "df2.loc[('droop',256,2)]['CV'][:] = cv_1_256_droop.iloc[1]\n",
    "df2.loc[('droop',256,3)]['CV'][:] = cv_1_256_droop.iloc[2]\n",
    "df2.loc[('droop',256,4)]['CV'][:] = cv_1_256_droop.iloc[3]\n",
    "df2.loc[('droop',256,5)]['CV'][:] = cv_1_256_droop.iloc[4]\n",
    "df2.loc[('droop',256,6)]['CV'][:] = cv_1_256_droop.iloc[5]\n",
    "df2.loc[('droop',256,7)]['CV'][:] = cv_1_256_droop.iloc[6]\n",
    "df2.loc[('droop',256,8)]['CV'][:] = cv_1_256_droop.iloc[7]\n",
    "df2.loc[('droop',256,9)]['CV'][:] = cv_1_256_droop.iloc[8]\n",
    "df2.loc[('droop',256,10)]['CV'][:] = cv_1_256_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bbcfe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',4,1)]['CV'][:] = cv_1_4_equal.iloc[0]\n",
    "df2.loc[('equal',4,2)]['CV'][:] = cv_1_4_equal.iloc[1]\n",
    "df2.loc[('equal',4,3)]['CV'][:] = cv_1_4_equal.iloc[2]\n",
    "df2.loc[('equal',4,4)]['CV'][:] = cv_1_4_equal.iloc[3]\n",
    "df2.loc[('equal',4,5)]['CV'][:] = cv_1_4_equal.iloc[4]\n",
    "df2.loc[('equal',4,6)]['CV'][:] = cv_1_4_equal.iloc[5]\n",
    "df2.loc[('equal',4,7)]['CV'][:] = cv_1_4_equal.iloc[6]\n",
    "df2.loc[('equal',4,8)]['CV'][:] = cv_1_4_equal.iloc[7]\n",
    "df2.loc[('equal',4,9)]['CV'][:] = cv_1_4_equal.iloc[8]\n",
    "df2.loc[('equal',4,10)]['CV'][:] = cv_1_4_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47b863dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',8,1)]['CV'][:] = cv_1_8_equal.iloc[0]\n",
    "df2.loc[('equal',8,2)]['CV'][:] = cv_1_8_equal.iloc[1]\n",
    "df2.loc[('equal',8,3)]['CV'][:] = cv_1_8_equal.iloc[2]\n",
    "df2.loc[('equal',8,4)]['CV'][:] = cv_1_8_equal.iloc[3]\n",
    "df2.loc[('equal',8,5)]['CV'][:] = cv_1_8_equal.iloc[4]\n",
    "df2.loc[('equal',8,6)]['CV'][:] = cv_1_8_equal.iloc[5]\n",
    "df2.loc[('equal',8,7)]['CV'][:] = cv_1_8_equal.iloc[6]\n",
    "df2.loc[('equal',8,8)]['CV'][:] = cv_1_8_equal.iloc[7]\n",
    "df2.loc[('equal',8,9)]['CV'][:] = cv_1_8_equal.iloc[8]\n",
    "df2.loc[('equal',8,10)]['CV'][:] = cv_1_8_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5625cc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',16,1)]['CV'][:] = cv_1_16_equal.iloc[0]\n",
    "df2.loc[('equal',16,2)]['CV'][:] = cv_1_16_equal.iloc[1]\n",
    "df2.loc[('equal',16,3)]['CV'][:] = cv_1_16_equal.iloc[2]\n",
    "df2.loc[('equal',16,4)]['CV'][:] = cv_1_16_equal.iloc[3]\n",
    "df2.loc[('equal',16,5)]['CV'][:] = cv_1_16_equal.iloc[4]\n",
    "df2.loc[('equal',16,6)]['CV'][:] = cv_1_16_equal.iloc[5]\n",
    "df2.loc[('equal',16,7)]['CV'][:] = cv_1_16_equal.iloc[6]\n",
    "df2.loc[('equal',16,8)]['CV'][:] = cv_1_16_equal.iloc[7]\n",
    "df2.loc[('equal',16,9)]['CV'][:] = cv_1_16_equal.iloc[8]\n",
    "df2.loc[('equal',16,10)]['CV'][:] = cv_1_16_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca2300f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',32,1)]['CV'][:] = cv_1_32_equal.iloc[0]\n",
    "df2.loc[('equal',32,2)]['CV'][:] = cv_1_32_equal.iloc[1]\n",
    "df2.loc[('equal',32,3)]['CV'][:] = cv_1_32_equal.iloc[2]\n",
    "df2.loc[('equal',32,4)]['CV'][:] = cv_1_32_equal.iloc[3]\n",
    "df2.loc[('equal',32,5)]['CV'][:] = cv_1_32_equal.iloc[4]\n",
    "df2.loc[('equal',32,6)]['CV'][:] = cv_1_32_equal.iloc[5]\n",
    "df2.loc[('equal',32,7)]['CV'][:] = cv_1_32_equal.iloc[6]\n",
    "df2.loc[('equal',32,8)]['CV'][:] = cv_1_32_equal.iloc[7]\n",
    "df2.loc[('equal',32,9)]['CV'][:] = cv_1_32_equal.iloc[8]\n",
    "df2.loc[('equal',32,10)]['CV'][:] = cv_1_32_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bbf8586",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',64,1)]['CV'][:] = cv_1_64_equal.iloc[0]\n",
    "df2.loc[('equal',64,2)]['CV'][:] = cv_1_64_equal.iloc[1]\n",
    "df2.loc[('equal',64,3)]['CV'][:] = cv_1_64_equal.iloc[2]\n",
    "df2.loc[('equal',64,4)]['CV'][:] = cv_1_64_equal.iloc[3]\n",
    "df2.loc[('equal',64,5)]['CV'][:] = cv_1_64_equal.iloc[4]\n",
    "df2.loc[('equal',64,6)]['CV'][:] = cv_1_64_equal.iloc[5]\n",
    "df2.loc[('equal',64,7)]['CV'][:] = cv_1_64_equal.iloc[6]\n",
    "df2.loc[('equal',64,8)]['CV'][:] = cv_1_64_equal.iloc[7]\n",
    "df2.loc[('equal',64,9)]['CV'][:] = cv_1_64_equal.iloc[8]\n",
    "df2.loc[('equal',64,10)]['CV'][:] = cv_1_64_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eec2d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',128,1)]['CV'][:] = cv_1_128_equal.iloc[0]\n",
    "df2.loc[('equal',128,2)]['CV'][:] = cv_1_128_equal.iloc[1]\n",
    "df2.loc[('equal',128,3)]['CV'][:] = cv_1_128_equal.iloc[2]\n",
    "df2.loc[('equal',128,4)]['CV'][:] = cv_1_128_equal.iloc[3]\n",
    "df2.loc[('equal',128,5)]['CV'][:] = cv_1_128_equal.iloc[4]\n",
    "df2.loc[('equal',128,6)]['CV'][:] = cv_1_128_equal.iloc[5]\n",
    "df2.loc[('equal',128,7)]['CV'][:] = cv_1_128_equal.iloc[6]\n",
    "df2.loc[('equal',128,8)]['CV'][:] = cv_1_128_equal.iloc[7]\n",
    "df2.loc[('equal',128,9)]['CV'][:] = cv_1_128_equal.iloc[8]\n",
    "df2.loc[('equal',128,10)]['CV'][:] = cv_1_128_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0671345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',256,1)]['CV'][:] = cv_1_256_equal.iloc[0]\n",
    "df2.loc[('equal',256,2)]['CV'][:] = cv_1_256_equal.iloc[1]\n",
    "df2.loc[('equal',256,3)]['CV'][:] = cv_1_256_equal.iloc[2]\n",
    "df2.loc[('equal',256,4)]['CV'][:] = cv_1_256_equal.iloc[3]\n",
    "df2.loc[('equal',256,5)]['CV'][:] = cv_1_256_equal.iloc[4]\n",
    "df2.loc[('equal',256,6)]['CV'][:] = cv_1_256_equal.iloc[5]\n",
    "df2.loc[('equal',256,7)]['CV'][:] = cv_1_256_equal.iloc[6]\n",
    "df2.loc[('equal',256,8)]['CV'][:] = cv_1_256_equal.iloc[7]\n",
    "df2.loc[('equal',256,9)]['CV'][:] = cv_1_256_equal.iloc[8]\n",
    "df2.loc[('equal',256,10)]['CV'][:] = cv_1_256_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7ba9d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('continuous',8,1)]['CV'][:] = cv_cont.iloc[0]\n",
    "df2.loc[('continuous',8,2)]['CV'][:] = cv_cont.iloc[1]\n",
    "df2.loc[('continuous',8,3)]['CV'][:] = cv_cont.iloc[2]\n",
    "df2.loc[('continuous',8,4)]['CV'][:] = cv_cont.iloc[3]\n",
    "df2.loc[('continuous',8,5)]['CV'][:] = cv_cont.iloc[4]\n",
    "df2.loc[('continuous',8,6)]['CV'][:] = cv_cont.iloc[5]\n",
    "df2.loc[('continuous',8,7)]['CV'][:] = cv_cont.iloc[6]\n",
    "df2.loc[('continuous',8,8)]['CV'][:] = cv_cont.iloc[7]\n",
    "df2.loc[('continuous',8,9)]['CV'][:] = cv_cont.iloc[8]\n",
    "df2.loc[('continuous',8,10)]['CV'][:] = cv_cont.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30a6954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',2,1)]['FR'][:] = fr_1_2_droop.iloc[0]\n",
    "df2.loc[('droop',2,2)]['FR'][:] = fr_1_2_droop.iloc[1]\n",
    "df2.loc[('droop',2,3)]['FR'][:] = fr_1_2_droop.iloc[2]\n",
    "df2.loc[('droop',2,4)]['FR'][:] = fr_1_2_droop.iloc[3]\n",
    "df2.loc[('droop',2,5)]['FR'][:] = fr_1_2_droop.iloc[4]\n",
    "df2.loc[('droop',2,6)]['FR'][:] = fr_1_2_droop.iloc[5]\n",
    "df2.loc[('droop',2,7)]['FR'][:] = fr_1_2_droop.iloc[6]\n",
    "df2.loc[('droop',2,8)]['FR'][:] = fr_1_2_droop.iloc[7]\n",
    "df2.loc[('droop',2,9)]['FR'][:] = fr_1_2_droop.iloc[8]\n",
    "df2.loc[('droop',2,10)]['FR'][:] = fr_1_2_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff28deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',4,1)]['FR'][:] = fr_1_4_droop.iloc[0]\n",
    "df2.loc[('droop',4,2)]['FR'][:] = fr_1_4_droop.iloc[1]\n",
    "df2.loc[('droop',4,3)]['FR'][:] = fr_1_4_droop.iloc[2]\n",
    "df2.loc[('droop',4,4)]['FR'][:] = fr_1_4_droop.iloc[3]\n",
    "df2.loc[('droop',4,5)]['FR'][:] = fr_1_4_droop.iloc[4]\n",
    "df2.loc[('droop',4,6)]['FR'][:] = fr_1_4_droop.iloc[5]\n",
    "df2.loc[('droop',4,7)]['FR'][:] = fr_1_4_droop.iloc[6]\n",
    "df2.loc[('droop',4,8)]['FR'][:] = fr_1_4_droop.iloc[7]\n",
    "df2.loc[('droop',4,9)]['FR'][:] = fr_1_4_droop.iloc[8]\n",
    "df2.loc[('droop',4,10)]['FR'][:] = fr_1_4_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9333094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',8,1)]['FR'][:] = fr_1_8_droop.iloc[0]\n",
    "df2.loc[('droop',8,2)]['FR'][:] = fr_1_8_droop.iloc[1]\n",
    "df2.loc[('droop',8,3)]['FR'][:] = fr_1_8_droop.iloc[2]\n",
    "df2.loc[('droop',8,4)]['FR'][:] = fr_1_8_droop.iloc[3]\n",
    "df2.loc[('droop',8,5)]['FR'][:] = fr_1_8_droop.iloc[4]\n",
    "df2.loc[('droop',8,6)]['FR'][:] = fr_1_8_droop.iloc[5]\n",
    "df2.loc[('droop',8,7)]['FR'][:] = fr_1_8_droop.iloc[6]\n",
    "df2.loc[('droop',8,8)]['FR'][:] = fr_1_8_droop.iloc[7]\n",
    "df2.loc[('droop',8,9)]['FR'][:] = fr_1_8_droop.iloc[8]\n",
    "df2.loc[('droop',8,10)]['FR'][:] = fr_1_8_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47805002",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',16,1)]['FR'][:] = fr_1_16_droop.iloc[0]\n",
    "df2.loc[('droop',16,2)]['FR'][:] = fr_1_16_droop.iloc[1]\n",
    "df2.loc[('droop',16,3)]['FR'][:] = fr_1_16_droop.iloc[2]\n",
    "df2.loc[('droop',16,4)]['FR'][:] = fr_1_16_droop.iloc[3]\n",
    "df2.loc[('droop',16,5)]['FR'][:] = fr_1_16_droop.iloc[4]\n",
    "df2.loc[('droop',16,6)]['FR'][:] = fr_1_16_droop.iloc[5]\n",
    "df2.loc[('droop',16,7)]['FR'][:] = fr_1_16_droop.iloc[6]\n",
    "df2.loc[('droop',16,8)]['FR'][:] = fr_1_16_droop.iloc[7]\n",
    "df2.loc[('droop',16,9)]['FR'][:] = fr_1_16_droop.iloc[8]\n",
    "df2.loc[('droop',16,10)]['FR'][:] = fr_1_16_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ca57a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',32,1)]['FR'][:] = fr_1_32_droop.iloc[0]\n",
    "df2.loc[('droop',32,2)]['FR'][:] = fr_1_32_droop.iloc[1]\n",
    "df2.loc[('droop',32,3)]['FR'][:] = fr_1_32_droop.iloc[2]\n",
    "df2.loc[('droop',32,4)]['FR'][:] = fr_1_32_droop.iloc[3]\n",
    "df2.loc[('droop',32,5)]['FR'][:] = fr_1_32_droop.iloc[4]\n",
    "df2.loc[('droop',32,6)]['FR'][:] = fr_1_32_droop.iloc[5]\n",
    "df2.loc[('droop',32,7)]['FR'][:] = fr_1_32_droop.iloc[6]\n",
    "df2.loc[('droop',32,8)]['FR'][:] = fr_1_32_droop.iloc[7]\n",
    "df2.loc[('droop',32,9)]['FR'][:] = fr_1_32_droop.iloc[8]\n",
    "df2.loc[('droop',32,10)]['FR'][:] = fr_1_32_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3cab243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',64,1)]['FR'][:] = fr_1_64_droop.iloc[0]\n",
    "df2.loc[('droop',64,2)]['FR'][:] = fr_1_64_droop.iloc[1]\n",
    "df2.loc[('droop',64,3)]['FR'][:] = fr_1_64_droop.iloc[2]\n",
    "df2.loc[('droop',64,4)]['FR'][:] = fr_1_64_droop.iloc[3]\n",
    "df2.loc[('droop',64,5)]['FR'][:] = fr_1_64_droop.iloc[4]\n",
    "df2.loc[('droop',64,6)]['FR'][:] = fr_1_64_droop.iloc[5]\n",
    "df2.loc[('droop',64,7)]['FR'][:] = fr_1_64_droop.iloc[6]\n",
    "df2.loc[('droop',64,8)]['FR'][:] = fr_1_64_droop.iloc[7]\n",
    "df2.loc[('droop',64,9)]['FR'][:] = fr_1_64_droop.iloc[8]\n",
    "df2.loc[('droop',64,10)]['FR'][:] = fr_1_64_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbbde76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',128,1)]['FR'][:] = fr_1_128_droop.iloc[0]\n",
    "df2.loc[('droop',128,2)]['FR'][:] = fr_1_128_droop.iloc[1]\n",
    "df2.loc[('droop',128,3)]['FR'][:] = fr_1_128_droop.iloc[2]\n",
    "df2.loc[('droop',128,4)]['FR'][:] = fr_1_128_droop.iloc[3]\n",
    "df2.loc[('droop',128,5)]['FR'][:] = fr_1_128_droop.iloc[4]\n",
    "df2.loc[('droop',128,6)]['FR'][:] = fr_1_128_droop.iloc[5]\n",
    "df2.loc[('droop',128,7)]['FR'][:] = fr_1_128_droop.iloc[6]\n",
    "df2.loc[('droop',128,8)]['FR'][:] = fr_1_128_droop.iloc[7]\n",
    "df2.loc[('droop',128,9)]['FR'][:] = fr_1_128_droop.iloc[8]\n",
    "df2.loc[('droop',128,10)]['FR'][:] = fr_1_128_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "486276b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',256,1)]['FR'][:] = fr_1_256_droop.iloc[0]\n",
    "df2.loc[('droop',256,2)]['FR'][:] = fr_1_256_droop.iloc[1]\n",
    "df2.loc[('droop',256,3)]['FR'][:] = fr_1_256_droop.iloc[2]\n",
    "df2.loc[('droop',256,4)]['FR'][:] = fr_1_256_droop.iloc[3]\n",
    "df2.loc[('droop',256,5)]['FR'][:] = fr_1_256_droop.iloc[4]\n",
    "df2.loc[('droop',256,6)]['FR'][:] = fr_1_256_droop.iloc[5]\n",
    "df2.loc[('droop',256,7)]['FR'][:] = fr_1_256_droop.iloc[6]\n",
    "df2.loc[('droop',256,8)]['FR'][:] = fr_1_256_droop.iloc[7]\n",
    "df2.loc[('droop',256,9)]['FR'][:] = fr_1_256_droop.iloc[8]\n",
    "df2.loc[('droop',256,10)]['FR'][:] = fr_1_256_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09aa4ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',4,1)]['FR'][:] = fr_1_4_equal.iloc[0]\n",
    "df2.loc[('equal',4,2)]['FR'][:] = fr_1_4_equal.iloc[1]\n",
    "df2.loc[('equal',4,3)]['FR'][:] = fr_1_4_equal.iloc[2]\n",
    "df2.loc[('equal',4,4)]['FR'][:] = fr_1_4_equal.iloc[3]\n",
    "df2.loc[('equal',4,5)]['FR'][:] = fr_1_4_equal.iloc[4]\n",
    "df2.loc[('equal',4,6)]['FR'][:] = fr_1_4_equal.iloc[5]\n",
    "df2.loc[('equal',4,7)]['FR'][:] = fr_1_4_equal.iloc[6]\n",
    "df2.loc[('equal',4,8)]['FR'][:] = fr_1_4_equal.iloc[7]\n",
    "df2.loc[('equal',4,9)]['FR'][:] = fr_1_4_equal.iloc[8]\n",
    "df2.loc[('equal',4,10)]['FR'][:] = fr_1_4_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ea5ba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',8,1)]['FR'][:] = fr_1_8_equal.iloc[0]\n",
    "df2.loc[('equal',8,2)]['FR'][:] = fr_1_8_equal.iloc[1]\n",
    "df2.loc[('equal',8,3)]['FR'][:] = fr_1_8_equal.iloc[2]\n",
    "df2.loc[('equal',8,4)]['FR'][:] = fr_1_8_equal.iloc[3]\n",
    "df2.loc[('equal',8,5)]['FR'][:] = fr_1_8_equal.iloc[4]\n",
    "df2.loc[('equal',8,6)]['FR'][:] = fr_1_8_equal.iloc[5]\n",
    "df2.loc[('equal',8,7)]['FR'][:] = fr_1_8_equal.iloc[6]\n",
    "df2.loc[('equal',8,8)]['FR'][:] = fr_1_8_equal.iloc[7]\n",
    "df2.loc[('equal',8,9)]['FR'][:] = fr_1_8_equal.iloc[8]\n",
    "df2.loc[('equal',8,10)]['FR'][:] = fr_1_8_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bdeff364",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',16,1)]['FR'][:] = fr_1_16_equal.iloc[0]\n",
    "df2.loc[('equal',16,2)]['FR'][:] = fr_1_16_equal.iloc[1]\n",
    "df2.loc[('equal',16,3)]['FR'][:] = fr_1_16_equal.iloc[2]\n",
    "df2.loc[('equal',16,4)]['FR'][:] = fr_1_16_equal.iloc[3]\n",
    "df2.loc[('equal',16,5)]['FR'][:] = fr_1_16_equal.iloc[4]\n",
    "df2.loc[('equal',16,6)]['FR'][:] = fr_1_16_equal.iloc[5]\n",
    "df2.loc[('equal',16,7)]['FR'][:] = fr_1_16_equal.iloc[6]\n",
    "df2.loc[('equal',16,8)]['FR'][:] = fr_1_16_equal.iloc[7]\n",
    "df2.loc[('equal',16,9)]['FR'][:] = fr_1_16_equal.iloc[8]\n",
    "df2.loc[('equal',16,10)]['FR'][:] = fr_1_16_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15515e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',32,1)]['FR'][:] = fr_1_32_equal.iloc[0]\n",
    "df2.loc[('equal',32,2)]['FR'][:] = fr_1_32_equal.iloc[1]\n",
    "df2.loc[('equal',32,3)]['FR'][:] = fr_1_32_equal.iloc[2]\n",
    "df2.loc[('equal',32,4)]['FR'][:] = fr_1_32_equal.iloc[3]\n",
    "df2.loc[('equal',32,5)]['FR'][:] = fr_1_32_equal.iloc[4]\n",
    "df2.loc[('equal',32,6)]['FR'][:] = fr_1_32_equal.iloc[5]\n",
    "df2.loc[('equal',32,7)]['FR'][:] = fr_1_32_equal.iloc[6]\n",
    "df2.loc[('equal',32,8)]['FR'][:] = fr_1_32_equal.iloc[7]\n",
    "df2.loc[('equal',32,9)]['FR'][:] = fr_1_32_equal.iloc[8]\n",
    "df2.loc[('equal',32,10)]['FR'][:] = fr_1_32_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e54f0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',64,1)]['FR'][:] = fr_1_64_equal.iloc[0]\n",
    "df2.loc[('equal',64,2)]['FR'][:] = fr_1_64_equal.iloc[1]\n",
    "df2.loc[('equal',64,3)]['FR'][:] = fr_1_64_equal.iloc[2]\n",
    "df2.loc[('equal',64,4)]['FR'][:] = fr_1_64_equal.iloc[3]\n",
    "df2.loc[('equal',64,5)]['FR'][:] = fr_1_64_equal.iloc[4]\n",
    "df2.loc[('equal',64,6)]['FR'][:] = fr_1_64_equal.iloc[5]\n",
    "df2.loc[('equal',64,7)]['FR'][:] = fr_1_64_equal.iloc[6]\n",
    "df2.loc[('equal',64,8)]['FR'][:] = fr_1_64_equal.iloc[7]\n",
    "df2.loc[('equal',64,9)]['FR'][:] = fr_1_64_equal.iloc[8]\n",
    "df2.loc[('equal',64,10)]['FR'][:] = fr_1_64_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87ae0c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',128,1)]['FR'][:] = fr_1_128_equal.iloc[0]\n",
    "df2.loc[('equal',128,2)]['FR'][:] = fr_1_128_equal.iloc[1]\n",
    "df2.loc[('equal',128,3)]['FR'][:] = fr_1_128_equal.iloc[2]\n",
    "df2.loc[('equal',128,4)]['FR'][:] = fr_1_128_equal.iloc[3]\n",
    "df2.loc[('equal',128,5)]['FR'][:] = fr_1_128_equal.iloc[4]\n",
    "df2.loc[('equal',128,6)]['FR'][:] = fr_1_128_equal.iloc[5]\n",
    "df2.loc[('equal',128,7)]['FR'][:] = fr_1_128_equal.iloc[6]\n",
    "df2.loc[('equal',128,8)]['FR'][:] = fr_1_128_equal.iloc[7]\n",
    "df2.loc[('equal',128,9)]['FR'][:] = fr_1_128_equal.iloc[8]\n",
    "df2.loc[('equal',128,10)]['FR'][:] = fr_1_128_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fed7ab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',256,1)]['FR'][:] = fr_1_256_equal.iloc[0]\n",
    "df2.loc[('equal',256,2)]['FR'][:] = fr_1_256_equal.iloc[1]\n",
    "df2.loc[('equal',256,3)]['FR'][:] = fr_1_256_equal.iloc[2]\n",
    "df2.loc[('equal',256,4)]['FR'][:] = fr_1_256_equal.iloc[3]\n",
    "df2.loc[('equal',256,5)]['FR'][:] = fr_1_256_equal.iloc[4]\n",
    "df2.loc[('equal',256,6)]['FR'][:] = fr_1_256_equal.iloc[5]\n",
    "df2.loc[('equal',256,7)]['FR'][:] = fr_1_256_equal.iloc[6]\n",
    "df2.loc[('equal',256,8)]['FR'][:] = fr_1_256_equal.iloc[7]\n",
    "df2.loc[('equal',256,9)]['FR'][:] = fr_1_256_equal.iloc[8]\n",
    "df2.loc[('equal',256,10)]['FR'][:] = fr_1_256_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eae768f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('continuous',8,1)]['FR'][:] = fr_cont.iloc[0]\n",
    "df2.loc[('continuous',8,2)]['FR'][:] = fr_cont.iloc[1]\n",
    "df2.loc[('continuous',8,3)]['FR'][:] = fr_cont.iloc[2]\n",
    "df2.loc[('continuous',8,4)]['FR'][:] = fr_cont.iloc[3]\n",
    "df2.loc[('continuous',8,5)]['FR'][:] = fr_cont.iloc[4]\n",
    "df2.loc[('continuous',8,6)]['FR'][:] = fr_cont.iloc[5]\n",
    "df2.loc[('continuous',8,7)]['FR'][:] = fr_cont.iloc[6]\n",
    "df2.loc[('continuous',8,8)]['FR'][:] = fr_cont.iloc[7]\n",
    "df2.loc[('continuous',8,9)]['FR'][:] = fr_cont.iloc[8]\n",
    "df2.loc[('continuous',8,10)]['FR'][:] = fr_cont.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7af80b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',2,1)]['CC_5'][:] = cc5_1_2_droop.iloc[0]\n",
    "df2.loc[('droop',2,2)]['CC_5'][:] = cc5_1_2_droop.iloc[1]\n",
    "df2.loc[('droop',2,3)]['CC_5'][:] = cc5_1_2_droop.iloc[2]\n",
    "df2.loc[('droop',2,4)]['CC_5'][:] = cc5_1_2_droop.iloc[3]\n",
    "df2.loc[('droop',2,5)]['CC_5'][:] = cc5_1_2_droop.iloc[4]\n",
    "df2.loc[('droop',2,6)]['CC_5'][:] = cc5_1_2_droop.iloc[5]\n",
    "df2.loc[('droop',2,7)]['CC_5'][:] = cc5_1_2_droop.iloc[6]\n",
    "df2.loc[('droop',2,8)]['CC_5'][:] = cc5_1_2_droop.iloc[7]\n",
    "df2.loc[('droop',2,9)]['CC_5'][:] = cc5_1_2_droop.iloc[8]\n",
    "df2.loc[('droop',2,10)]['CC_5'][:] = cc5_1_2_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96b1c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',4,1)]['CC_5'][:] = cc5_1_4_droop.iloc[0]\n",
    "df2.loc[('droop',4,2)]['CC_5'][:] = cc5_1_4_droop.iloc[1]\n",
    "df2.loc[('droop',4,3)]['CC_5'][:] = cc5_1_4_droop.iloc[2]\n",
    "df2.loc[('droop',4,4)]['CC_5'][:] = cc5_1_4_droop.iloc[3]\n",
    "df2.loc[('droop',4,5)]['CC_5'][:] = cc5_1_4_droop.iloc[4]\n",
    "df2.loc[('droop',4,6)]['CC_5'][:] = cc5_1_4_droop.iloc[5]\n",
    "df2.loc[('droop',4,7)]['CC_5'][:] = cc5_1_4_droop.iloc[6]\n",
    "df2.loc[('droop',4,8)]['CC_5'][:] = cc5_1_4_droop.iloc[7]\n",
    "df2.loc[('droop',4,9)]['CC_5'][:] = cc5_1_4_droop.iloc[8]\n",
    "df2.loc[('droop',4,10)]['CC_5'][:] = cc5_1_4_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0964bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',8,1)]['CC_5'][:] = cc5_1_8_droop.iloc[0]\n",
    "df2.loc[('droop',8,2)]['CC_5'][:] = cc5_1_8_droop.iloc[1]\n",
    "df2.loc[('droop',8,3)]['CC_5'][:] = cc5_1_8_droop.iloc[2]\n",
    "df2.loc[('droop',8,4)]['CC_5'][:] = cc5_1_8_droop.iloc[3]\n",
    "df2.loc[('droop',8,5)]['CC_5'][:] = cc5_1_8_droop.iloc[4]\n",
    "df2.loc[('droop',8,6)]['CC_5'][:] = cc5_1_8_droop.iloc[5]\n",
    "df2.loc[('droop',8,7)]['CC_5'][:] = cc5_1_8_droop.iloc[6]\n",
    "df2.loc[('droop',8,8)]['CC_5'][:] = cc5_1_8_droop.iloc[7]\n",
    "df2.loc[('droop',8,9)]['CC_5'][:] = cc5_1_8_droop.iloc[8]\n",
    "df2.loc[('droop',8,10)]['CC_5'][:] = cc5_1_8_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "624b5fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',16,1)]['CC_5'][:] = cc5_1_16_droop.iloc[0]\n",
    "df2.loc[('droop',16,2)]['CC_5'][:] = cc5_1_16_droop.iloc[1]\n",
    "df2.loc[('droop',16,3)]['CC_5'][:] = cc5_1_16_droop.iloc[2]\n",
    "df2.loc[('droop',16,4)]['CC_5'][:] = cc5_1_16_droop.iloc[3]\n",
    "df2.loc[('droop',16,5)]['CC_5'][:] = cc5_1_16_droop.iloc[4]\n",
    "df2.loc[('droop',16,6)]['CC_5'][:] = cc5_1_16_droop.iloc[5]\n",
    "df2.loc[('droop',16,7)]['CC_5'][:] = cc5_1_16_droop.iloc[6]\n",
    "df2.loc[('droop',16,8)]['CC_5'][:] = cc5_1_16_droop.iloc[7]\n",
    "df2.loc[('droop',16,9)]['CC_5'][:] = cc5_1_16_droop.iloc[8]\n",
    "df2.loc[('droop',16,10)]['CC_5'][:] = cc5_1_16_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8abd76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',32,1)]['CC_5'][:] = cc5_1_32_droop.iloc[0]\n",
    "df2.loc[('droop',32,2)]['CC_5'][:] = cc5_1_32_droop.iloc[1]\n",
    "df2.loc[('droop',32,3)]['CC_5'][:] = cc5_1_32_droop.iloc[2]\n",
    "df2.loc[('droop',32,4)]['CC_5'][:] = cc5_1_32_droop.iloc[3]\n",
    "df2.loc[('droop',32,5)]['CC_5'][:] = cc5_1_32_droop.iloc[4]\n",
    "df2.loc[('droop',32,6)]['CC_5'][:] = cc5_1_32_droop.iloc[5]\n",
    "df2.loc[('droop',32,7)]['CC_5'][:] = cc5_1_32_droop.iloc[6]\n",
    "df2.loc[('droop',32,8)]['CC_5'][:] = cc5_1_32_droop.iloc[7]\n",
    "df2.loc[('droop',32,9)]['CC_5'][:] = cc5_1_32_droop.iloc[8]\n",
    "df2.loc[('droop',32,10)]['CC_5'][:] = cc5_1_32_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e6220a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',64,1)]['CC_5'][:] = cc5_1_64_droop.iloc[0]\n",
    "df2.loc[('droop',64,2)]['CC_5'][:] = cc5_1_64_droop.iloc[1]\n",
    "df2.loc[('droop',64,3)]['CC_5'][:] = cc5_1_64_droop.iloc[2]\n",
    "df2.loc[('droop',64,4)]['CC_5'][:] = cc5_1_64_droop.iloc[3]\n",
    "df2.loc[('droop',64,5)]['CC_5'][:] = cc5_1_64_droop.iloc[4]\n",
    "df2.loc[('droop',64,6)]['CC_5'][:] = cc5_1_64_droop.iloc[5]\n",
    "df2.loc[('droop',64,7)]['CC_5'][:] = cc5_1_64_droop.iloc[6]\n",
    "df2.loc[('droop',64,8)]['CC_5'][:] = cc5_1_64_droop.iloc[7]\n",
    "df2.loc[('droop',64,9)]['CC_5'][:] = cc5_1_64_droop.iloc[8]\n",
    "df2.loc[('droop',64,10)]['CC_5'][:] = cc5_1_64_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1abc5f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',128,1)]['CC_5'][:] = cc5_1_128_droop.iloc[0]\n",
    "df2.loc[('droop',128,2)]['CC_5'][:] = cc5_1_128_droop.iloc[1]\n",
    "df2.loc[('droop',128,3)]['CC_5'][:] = cc5_1_128_droop.iloc[2]\n",
    "df2.loc[('droop',128,4)]['CC_5'][:] = cc5_1_128_droop.iloc[3]\n",
    "df2.loc[('droop',128,5)]['CC_5'][:] = cc5_1_128_droop.iloc[4]\n",
    "df2.loc[('droop',128,6)]['CC_5'][:] = cc5_1_128_droop.iloc[5]\n",
    "df2.loc[('droop',128,7)]['CC_5'][:] = cc5_1_128_droop.iloc[6]\n",
    "df2.loc[('droop',128,8)]['CC_5'][:] = cc5_1_128_droop.iloc[7]\n",
    "df2.loc[('droop',128,9)]['CC_5'][:] = cc5_1_128_droop.iloc[8]\n",
    "df2.loc[('droop',128,10)]['CC_5'][:] = cc5_1_128_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09322b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('droop',256,1)]['CC_5'][:] = cc5_1_256_droop.iloc[0]\n",
    "df2.loc[('droop',256,2)]['CC_5'][:] = cc5_1_256_droop.iloc[1]\n",
    "df2.loc[('droop',256,3)]['CC_5'][:] = cc5_1_256_droop.iloc[2]\n",
    "df2.loc[('droop',256,4)]['CC_5'][:] = cc5_1_256_droop.iloc[3]\n",
    "df2.loc[('droop',256,5)]['CC_5'][:] = cc5_1_256_droop.iloc[4]\n",
    "df2.loc[('droop',256,6)]['CC_5'][:] = cc5_1_256_droop.iloc[5]\n",
    "df2.loc[('droop',256,7)]['CC_5'][:] = cc5_1_256_droop.iloc[6]\n",
    "df2.loc[('droop',256,8)]['CC_5'][:] = cc5_1_256_droop.iloc[7]\n",
    "df2.loc[('droop',256,9)]['CC_5'][:] = cc5_1_256_droop.iloc[8]\n",
    "df2.loc[('droop',256,10)]['CC_5'][:] = cc5_1_256_droop.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c354a58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',4,1)]['CC_5'][:] = cc5_1_4_equal.iloc[0]\n",
    "df2.loc[('equal',4,2)]['CC_5'][:] = cc5_1_4_equal.iloc[1]\n",
    "df2.loc[('equal',4,3)]['CC_5'][:] = cc5_1_4_equal.iloc[2]\n",
    "df2.loc[('equal',4,4)]['CC_5'][:] = cc5_1_4_equal.iloc[3]\n",
    "df2.loc[('equal',4,5)]['CC_5'][:] = cc5_1_4_equal.iloc[4]\n",
    "df2.loc[('equal',4,6)]['CC_5'][:] = cc5_1_4_equal.iloc[5]\n",
    "df2.loc[('equal',4,7)]['CC_5'][:] = cc5_1_4_equal.iloc[6]\n",
    "df2.loc[('equal',4,8)]['CC_5'][:] = cc5_1_4_equal.iloc[7]\n",
    "df2.loc[('equal',4,9)]['CC_5'][:] = cc5_1_4_equal.iloc[8]\n",
    "df2.loc[('equal',4,10)]['CC_5'][:] = cc5_1_4_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "981391fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',8,1)]['CC_5'][:] = cc5_1_8_equal.iloc[0]\n",
    "df2.loc[('equal',8,2)]['CC_5'][:] = cc5_1_8_equal.iloc[1]\n",
    "df2.loc[('equal',8,3)]['CC_5'][:] = cc5_1_8_equal.iloc[2]\n",
    "df2.loc[('equal',8,4)]['CC_5'][:] = cc5_1_8_equal.iloc[3]\n",
    "df2.loc[('equal',8,5)]['CC_5'][:] = cc5_1_8_equal.iloc[4]\n",
    "df2.loc[('equal',8,6)]['CC_5'][:] = cc5_1_8_equal.iloc[5]\n",
    "df2.loc[('equal',8,7)]['CC_5'][:] = cc5_1_8_equal.iloc[6]\n",
    "df2.loc[('equal',8,8)]['CC_5'][:] = cc5_1_8_equal.iloc[7]\n",
    "df2.loc[('equal',8,9)]['CC_5'][:] = cc5_1_8_equal.iloc[8]\n",
    "df2.loc[('equal',8,10)]['CC_5'][:] = cc5_1_8_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "da906319",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',16,1)]['CC_5'][:] = cc5_1_16_equal.iloc[0]\n",
    "df2.loc[('equal',16,2)]['CC_5'][:] = cc5_1_16_equal.iloc[1]\n",
    "df2.loc[('equal',16,3)]['CC_5'][:] = cc5_1_16_equal.iloc[2]\n",
    "df2.loc[('equal',16,4)]['CC_5'][:] = cc5_1_16_equal.iloc[3]\n",
    "df2.loc[('equal',16,5)]['CC_5'][:] = cc5_1_16_equal.iloc[4]\n",
    "df2.loc[('equal',16,6)]['CC_5'][:] = cc5_1_16_equal.iloc[5]\n",
    "df2.loc[('equal',16,7)]['CC_5'][:] = cc5_1_16_equal.iloc[6]\n",
    "df2.loc[('equal',16,8)]['CC_5'][:] = cc5_1_16_equal.iloc[7]\n",
    "df2.loc[('equal',16,9)]['CC_5'][:] = cc5_1_16_equal.iloc[8]\n",
    "df2.loc[('equal',16,10)]['CC_5'][:] = cc5_1_16_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f3a7f973",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',32,1)]['CC_5'][:] = cc5_1_32_equal.iloc[0]\n",
    "df2.loc[('equal',32,2)]['CC_5'][:] = cc5_1_32_equal.iloc[1]\n",
    "df2.loc[('equal',32,3)]['CC_5'][:] = cc5_1_32_equal.iloc[2]\n",
    "df2.loc[('equal',32,4)]['CC_5'][:] = cc5_1_32_equal.iloc[3]\n",
    "df2.loc[('equal',32,5)]['CC_5'][:] = cc5_1_32_equal.iloc[4]\n",
    "df2.loc[('equal',32,6)]['CC_5'][:] = cc5_1_32_equal.iloc[5]\n",
    "df2.loc[('equal',32,7)]['CC_5'][:] = cc5_1_32_equal.iloc[6]\n",
    "df2.loc[('equal',32,8)]['CC_5'][:] = cc5_1_32_equal.iloc[7]\n",
    "df2.loc[('equal',32,9)]['CC_5'][:] = cc5_1_32_equal.iloc[8]\n",
    "df2.loc[('equal',32,10)]['CC_5'][:] = cc5_1_32_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6e56cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',64,1)]['CC_5'][:] = cc5_1_64_equal.iloc[0]\n",
    "df2.loc[('equal',64,2)]['CC_5'][:] = cc5_1_64_equal.iloc[1]\n",
    "df2.loc[('equal',64,3)]['CC_5'][:] = cc5_1_64_equal.iloc[2]\n",
    "df2.loc[('equal',64,4)]['CC_5'][:] = cc5_1_64_equal.iloc[3]\n",
    "df2.loc[('equal',64,5)]['CC_5'][:] = cc5_1_64_equal.iloc[4]\n",
    "df2.loc[('equal',64,6)]['CC_5'][:] = cc5_1_64_equal.iloc[5]\n",
    "df2.loc[('equal',64,7)]['CC_5'][:] = cc5_1_64_equal.iloc[6]\n",
    "df2.loc[('equal',64,8)]['CC_5'][:] = cc5_1_64_equal.iloc[7]\n",
    "df2.loc[('equal',64,9)]['CC_5'][:] = cc5_1_64_equal.iloc[8]\n",
    "df2.loc[('equal',64,10)]['CC_5'][:] = cc5_1_64_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1e7ab213",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',128,1)]['CC_5'][:] = cc5_1_128_equal.iloc[0]\n",
    "df2.loc[('equal',128,2)]['CC_5'][:] = cc5_1_128_equal.iloc[1]\n",
    "df2.loc[('equal',128,3)]['CC_5'][:] = cc5_1_128_equal.iloc[2]\n",
    "df2.loc[('equal',128,4)]['CC_5'][:] = cc5_1_128_equal.iloc[3]\n",
    "df2.loc[('equal',128,5)]['CC_5'][:] = cc5_1_128_equal.iloc[4]\n",
    "df2.loc[('equal',128,6)]['CC_5'][:] = cc5_1_128_equal.iloc[5]\n",
    "df2.loc[('equal',128,7)]['CC_5'][:] = cc5_1_128_equal.iloc[6]\n",
    "df2.loc[('equal',128,8)]['CC_5'][:] = cc5_1_128_equal.iloc[7]\n",
    "df2.loc[('equal',128,9)]['CC_5'][:] = cc5_1_128_equal.iloc[8]\n",
    "df2.loc[('equal',128,10)]['CC_5'][:] = cc5_1_128_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1a1345e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('equal',256,1)]['CC_5'][:] = cc5_1_256_equal.iloc[0]\n",
    "df2.loc[('equal',256,2)]['CC_5'][:] = cc5_1_256_equal.iloc[1]\n",
    "df2.loc[('equal',256,3)]['CC_5'][:] = cc5_1_256_equal.iloc[2]\n",
    "df2.loc[('equal',256,4)]['CC_5'][:] = cc5_1_256_equal.iloc[3]\n",
    "df2.loc[('equal',256,5)]['CC_5'][:] = cc5_1_256_equal.iloc[4]\n",
    "df2.loc[('equal',256,6)]['CC_5'][:] = cc5_1_256_equal.iloc[5]\n",
    "df2.loc[('equal',256,7)]['CC_5'][:] = cc5_1_256_equal.iloc[6]\n",
    "df2.loc[('equal',256,8)]['CC_5'][:] = cc5_1_256_equal.iloc[7]\n",
    "df2.loc[('equal',256,9)]['CC_5'][:] = cc5_1_256_equal.iloc[8]\n",
    "df2.loc[('equal',256,10)]['CC_5'][:] = cc5_1_256_equal.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "55f11a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[('continuous',8,1)]['CC_5'][:] = cc5_cont.iloc[0]\n",
    "df2.loc[('continuous',8,2)]['CC_5'][:] = cc5_cont.iloc[1]\n",
    "df2.loc[('continuous',8,3)]['CC_5'][:] = cc5_cont.iloc[2]\n",
    "df2.loc[('continuous',8,4)]['CC_5'][:] = cc5_cont.iloc[3]\n",
    "df2.loc[('continuous',8,5)]['CC_5'][:] = cc5_cont.iloc[4]\n",
    "df2.loc[('continuous',8,6)]['CC_5'][:] = cc5_cont.iloc[5]\n",
    "df2.loc[('continuous',8,7)]['CC_5'][:] = cc5_cont.iloc[6]\n",
    "df2.loc[('continuous',8,8)]['CC_5'][:] = cc5_cont.iloc[7]\n",
    "df2.loc[('continuous',8,9)]['CC_5'][:] = cc5_cont.iloc[8]\n",
    "df2.loc[('continuous',8,10)]['CC_5'][:] = cc5_cont.iloc[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efea61c",
   "metadata": {},
   "source": [
    "Save the dataframe to a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "061ec760",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_pickle('C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data\\\\microcircuit_77175_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
