{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30679a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import elephant\n",
    "import quantities as pq\n",
    "import neo\n",
    "import sys\n",
    "from scipy.stats import ks_2samp\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "from elephant.conversion import BinnedSpikeTrain\n",
    "from elephant.spike_train_correlation import correlation_coefficient\n",
    "sys.setrecursionlimit(10000)\n",
    "from pathlib import Path\n",
    "# If seaborn and elephant not available, run the sommands:\n",
    "# !{sys.executable} -m pip install elephant\n",
    "# !{sys.executable} -m pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0aa391",
   "metadata": {},
   "source": [
    "Want to calculate the CC correlation between each excitatory neuron and the first inhibitory neuron. Code for retrieveing spike times from neuron 1 in inhibitory population. Remember that we first record all 10 000 excitatory neurons, so the first inhibitory neuron is the neuron with id 10 001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db468204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_inh(inh):\n",
    "    \"\"\"\n",
    "    Takes in path to dat file of inhibitory population spike times.\n",
    "    \n",
    "    This function retrieves the spike times of the first neuron in the inhibitory population.\n",
    "    Return it as a spiketrain object.\n",
    "    \"\"\"\n",
    "    #inh = pd.read_csv(path, skiprows=2, sep='\\t')\n",
    "    spike_data = inh.sort_values(by='time_ms')\n",
    "    grouped = spike_data.groupby(spike_data['sender'])\n",
    "    t = np.array(grouped.get_group(10001)['time_ms'])\n",
    "    spiketrain = neo.core.SpikeTrain(t * pq.ms, t_start=0*pq.ms, t_stop=10000*pq.ms)\n",
    "    \n",
    "    return spiketrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76b9f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ccs(exc, first_inh, bs=5):\n",
    "    \"\"\"\n",
    "    Get the CC between each excitatory neuron and first inhibitory neuron.\n",
    "    CC = (x-mean(x))(y-mean(y))/sqrt((x-mean(x))^2(y-mean(y))^2)\n",
    "    \"\"\"\n",
    "    # get all spike trains of excitatory neurons\n",
    "    spike_data = exc.sort_values(by='time_ms')\n",
    "    grouped = spike_data.groupby(spike_data['sender'])\n",
    "    spike_trains = []\n",
    "    for name, group in grouped:\n",
    "        t = np.asarray(group['time_ms'])\n",
    "        spiketrain = neo.core.SpikeTrain(t * pq.ms, t_start=0*pq.ms, t_stop=10000*pq.ms)\n",
    "        spike_trains.append(spiketrain)\n",
    "    \n",
    "    correlations = []\n",
    "    for i in range(len(spike_trains)):\n",
    "        # calculate cc matrix for the pair of spiketrains\n",
    "        cc_matrix = correlation_coefficient(BinnedSpikeTrain([spike_trains[i],first_inh], bin_size=bs*pq.ms))\n",
    "        # retrieve element not on diagonala\n",
    "        cc = cc_matrix[1,0]\n",
    "        correlations.append(cc)\n",
    "        \n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94ba8015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_ccs(exc,inh,bs=5):\n",
    "    \"\"\"\n",
    "    This function takes in two nested lists. exc is list of tables of spike times for excitatory popuulation.\n",
    "    Same for inh but inhibitory population.\n",
    "    \"\"\"\n",
    "    cc_list = list()\n",
    "    for i in range(1,11):\n",
    "        first_inh = get_first_inh(inh[i])\n",
    "        exc_ccs = get_ccs(exc[i],first_inh,bs=bs)\n",
    "        cc_list.append(exc_ccs)\n",
    "    return cc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011367bf",
   "metadata": {},
   "source": [
    "What we need to do, is model by model retrieve all excitatory and inhibitory spike time files, save in list of tables. Then send these into the get_all_ccs function to retrieve cc list for all seed values and all neurons. Remember to do this for all .\n",
    "\n",
    "All files from rounded spike times and delay 1.0 to 2.0 have same file names, can use function below to retrieve the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1466e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_1_2(spike_path):\n",
    "    \"\"\"\n",
    "    Get spike data from brunel model with rounded spike times and delays drawn from discrete interval [1.0, 2.0].\n",
    "    Send in any path we need.\n",
    "    \"\"\"\n",
    "    #spike_path = 'C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\organized_spike_data\\\\resolution_1_2\\\\brunel_rounding_1_2'\n",
    "    exc = {}\n",
    "    for i in range(1,11):\n",
    "        exc[i] = pd.read_csv(r'{}/brunel_rounding_True_delay_1.0_2.0_seed_{}_spikes_exc-12502-0.dat'.format(spike_path, i),\n",
    "                             skiprows=2,sep='\\t')\n",
    "\n",
    "    inh = {}\n",
    "    for i in range(1,11):\n",
    "        inh[i] = pd.read_csv(r'{}/brunel_rounding_True_delay_1.0_2.0_seed_{}_spikes_inh-12503-0.dat'.format(spike_path, i),\n",
    "                             skiprows=2,sep='\\t')\n",
    "    return exc, inh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6ad18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_paths = ['C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\organized_spike_data\\\\resolution_1_2\\\\brunel_rounding_1_2\\\\large_J',\n",
    "               'C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\organized_spike_data\\\\resolution_1_4\\\\brunel_rounding_1_2\\\\large_J',\n",
    "               'C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\organized_spike_data\\\\resolution_1_8\\\\brunel_rounding_1_2\\\\large_J',\n",
    "               'C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\organized_spike_data\\\\resolution_1_16\\\\brunel_rounding_1_2\\\\large_J',\n",
    "               'C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\organized_spike_data\\\\resolution_1_32\\\\brunel_rounding_1_2\\\\large_J',\n",
    "               'C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\organized_spike_data\\\\resolution_1_64\\\\brunel_rounding_1_2\\\\large_J',\n",
    "               'C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\organized_spike_data\\\\resolution_1_128\\\\brunel_rounding_1_2\\\\large_J',\n",
    "               'C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\organized_spike_data\\\\resolution_1_256\\\\brunel_rounding_1_2\\\\large_J']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8b9334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exc, inh = round_1_2(spike_paths[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5918a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_list_5 = get_all_ccs(exc,inh,bs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a32396b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_list_10 = get_all_ccs(exc,inh,bs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0fd7846",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_list_20 = get_all_ccs(exc,inh,bs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf13d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_list_50 = get_all_ccs(exc,inh,bs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "765362a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_5 = pd.DataFrame(cc_list_5)\n",
    "cc_10 = pd.DataFrame(cc_list_10)\n",
    "cc_20 = pd.DataFrame(cc_list_20)\n",
    "cc_50 = pd.DataFrame(cc_list_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d711ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_5.to_pickle('{}\\cc_df_5.pkl'.format(spike_paths[7]))\n",
    "cc_10.to_pickle('{}\\cc_df_10.pkl'.format(spike_paths[7]))\n",
    "cc_20.to_pickle('{}\\cc_df_20.pkl'.format(spike_paths[7]))\n",
    "cc_50.to_pickle('{}\\cc_df_50.pkl'.format(spike_paths[7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f04ac4",
   "metadata": {},
   "source": [
    "And now for the qual delays. Must be done more by hans as delay values are different for each model resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ad0361bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal():\n",
    "    \"\"\"\n",
    "    Get spike data from brunel model with rounded spike times and delays drawn from discrete interval [1.0, 2.0].\n",
    "    Send in any path we need.\n",
    "    \"\"\"\n",
    "    spike_path = 'C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\organized_spike_data\\\\resolution_1_8\\\\brunel_continuous\\\\large_J'\n",
    "    exc = {}\n",
    "    for i in range(1,11):\n",
    "        exc[i] = pd.read_csv(r'{}/brunel_continuous_delay_1.0_2.0_seed_{}_spikes_exc-12502-0.dat'.format(spike_path, i),\n",
    "                             skiprows=2,sep='\\t')\n",
    "\n",
    "    inh = {}\n",
    "    for i in range(1,11):\n",
    "        inh[i] = pd.read_csv(r'{}/brunel_continuous__delay_1.0_2.0_seed_{}_spikes_inh-12503-0.dat'.format(spike_path, i),\n",
    "                             skiprows=2,sep='\\t')\n",
    "    return exc, inh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "044b0573",
   "metadata": {},
   "outputs": [],
   "source": [
    "exc, inh = equal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "df7696f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_list_5 = get_all_ccs(exc,inh,bs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8ea7bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_list_10 = get_all_ccs(exc,inh,bs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "74fb80a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_list_20 = get_all_ccs(exc,inh,bs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "803ca25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_list_50 = get_all_ccs(exc,inh,bs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "64c95e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_5 = pd.DataFrame(cc_list_5)\n",
    "cc_10 = pd.DataFrame(cc_list_10)\n",
    "cc_20 = pd.DataFrame(cc_list_20)\n",
    "cc_50 = pd.DataFrame(cc_list_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dc155d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\organized_spike_data\\\\resolution_1_8\\\\brunel_continuous\\\\large_J'\n",
    "cc_5.to_pickle('{}\\cc_df_5.pkl'.format(p))\n",
    "cc_10.to_pickle('{}\\cc_df_10.pkl'.format(p))\n",
    "cc_20.to_pickle('{}\\cc_df_20.pkl'.format(p))\n",
    "cc_50.to_pickle('{}\\cc_df_50.pkl'.format(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313a702c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "666457db",
   "metadata": {},
   "source": [
    "# Microcircuit\n",
    "Get cc for all neurons microcircuit model. We will calculate it as the correlation between the firs tneuron in the group and all other neurons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdd22e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ccs(data,bs=5):\n",
    "    spike_data = data.sort_values(by='time_ms')\n",
    "    grouped = spike_data.groupby(spike_data['sender'])\n",
    "    spike_trains = []\n",
    "    for name, group in grouped:\n",
    "        \"\"\"\n",
    "        The groups come in order, so that the first group is the first neuron in the population.\n",
    "        \"\"\"\n",
    "        t = np.asarray(group['time_ms'])\n",
    "        spiketrain = neo.core.SpikeTrain(t * pq.ms, t_start=0*pq.ms, t_stop=10000*pq.ms)\n",
    "        spike_trains.append(spiketrain)\n",
    "    \"\"\"\n",
    "    Now that we have all the spike trains, we can calculate the correlations between the first neuron in the population,\n",
    "    and the rest.\n",
    "    \"\"\"\n",
    "    correlations = []\n",
    "    for i in range(len(spike_trains)):\n",
    "        # could make sense to let range go from 1 and up, not include cc of first neruon with itself. But nice to have\n",
    "        # same length for this statistic as the others. And all models will have this so okay.\n",
    "        \n",
    "        # calculate cc matrix for the pair of spiketrains\n",
    "        cc_matrix = correlation_coefficient(BinnedSpikeTrain([spike_trains[i],spike_trains[0]], bin_size=bs*pq.ms))\n",
    "        # retrieve element not on diagonal\n",
    "        cc = cc_matrix[1,0]\n",
    "        correlations.append(cc)\n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e8b87c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cc_dfs(path):\n",
    "    for p in path.iterdir():\n",
    "        # resolution folder\n",
    "        cc_list = list()\n",
    "        for f in p.iterdir():\n",
    "            if f.is_dir():\n",
    "                data = pd.read_pickle(r'{}\\spike_data.pkl'.format(f))\n",
    "                ccs = get_ccs(data)\n",
    "                cc_list.append(cvs)\n",
    "        # iterated through all seed folders and calculated CV values.\n",
    "        df = pd.DataFrame(cc_list) # save ccs to dataframe\n",
    "        df.to_csv(r'{}\\77175_cc5.csv'.format(p)) # save as csv file      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903abd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data\\\\droop')\n",
    "create_cc_dfs(path)\n",
    "\n",
    "path = Path('C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data\\\\equal')\n",
    "create_cc_dfs(path)\n",
    "\n",
    "path = Path('C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\microcircuit_spike_data\\\\continuous')\n",
    "create_cc_dfs(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
